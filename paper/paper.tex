\documentclass[12pt]{article}

% General
\usepackage[round]{natbib}
\usepackage{setspace}
\usepackage{geometry}
\usepackage[section]{placeins}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{titlesec}
\usepackage[page]{appendix}
\usepackage{enumerate}

% Tables/Figures
\usepackage{lscape}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{tabularx}
\usepackage{ragged2e}
\newcolumntype{Y}{>{\RaggedRight\arraybackslash}X}
\usepackage{pdflscape}
\usepackage{afterpage}

% Math
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{dsfont}

\usepackage{tikz}

% \doublespacing
\onehalfspacing
% \singlespacing

% \numberwithin{equation}{section}

\geometry{paper=letterpaper, margin=1in}
\captionsetup{font=small}

% Code
\usepackage{textcomp}
\usepackage{sourcecodepro}
\usepackage{listings}
\definecolor{commentgrey}{gray}{0.45}
\definecolor{backgray}{gray}{0.96}
\lstset{
  basicstyle=\footnotesize\ttfamily, keywordstyle=\footnotesize,
  backgroundcolor=\color{backgray}, commentstyle=\color{commentgrey},
  frame=single, rulecolor=\color{backgray}, showstringspaces=false,
  breakatwhitespace=true, breaklines=true, upquote=true,
  numbers=left, numberstyle=\footnotesize\color{commentgrey}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% User-defined LaTeX commands
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand*{\expp}[1]{\exp\left(#1\right)}
\newcommand*{\foralls}{\ \forall \ }
\newcommand*{\st}{\text{ s.t. }}
\newcommand*{\E}{\mathbb E}
\newcommand*{\R}{\mathbb R}
\newcommand*{\I}{\mathds{1}}
\newcommand*{\Prob}{\mathbb P}
\newcommand*{\convas}[1]{\xrightarrow{#1}}
\newcommand*{\conv}{\convas{}}
\newcommand*{\cond}{\;\ifnum\currentgrouptype=16 \middle\fi|\;}
\newcommand*{\defeq}{%
  \mathrel{\overset{\makebox[0pt]{\mbox{\normalfont\tiny\sffamily def}}}{=}}}
\newcommand*{\notorth}{\ensuremath{\perp\!\!\!\!\!\!\diagup\!\!\!\!\!\!\perp}}
\newcommand*{\orth}{\ensuremath{\perp\!\!\!\perp}}
\newcommand*{\evalat}{\,\big\rvert}
\newcommand*{\dif}{\,d}
\newcommand*{\difto}[1]{\,d^#1}
\newcommand*{\difbot}[1]{\frac{d}{d#1}}
\newcommand*{\partialbot}[1]{\frac{\partial}{\partial#1}}
\newcommand*{\m}[1]{\textbf{#1}}
\newcommand*{\bmath}[1]{\boldsymbol{#1}}

\newcommand*{\yestag}{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand*{\notaligned}[1]{\noalign{$\displaystyle #1$}}
\newcommand*{\ttilde}{{\raise.17ex\hbox{$\scriptstyle\sim$}}}

\makeatletter
\newsavebox{\mybox}\newsavebox{\mysim}
\newcommand*{\distas}[1]{%
  \savebox{\mybox}{\hbox{\kern3pt$\scriptstyle#1$\kern3pt}}%
  \savebox{\mysim}{\hbox{$\sim$}}%
  \mathbin{\overset{#1}{\kern\z@\resizebox{\wd\mybox}{\ht\mysim}{$\sim$}}}%
}
\makeatother
\newcommand*{\dist}{\sim}
\newcommand*{\distiid}{\distas{\text{i.i.d}}}

\makeatletter
\def\moverlay{\mathpalette\mov@rlay}
\def\mov@rlay#1#2{\leavevmode\vtop{%
   \baselineskip\z@skip \lineskiplimit-\maxdimen
   \ialign{\hfil$\m@th#1##$\hfil\cr#2\crcr}}}
\newcommand*{\charfusion}[3][\mathord]{
  #1{\ifx#1\mathop\vphantom{#2}\fi\mathpalette\mov@rlay{#2\cr#3}}
  \ifx#1\mathop\expandafter\displaylimits\fi}
\makeatother
\newcommand*{\cupdot}{\charfusion[\mathbin]{\cup}{\cdot}}
\newcommand*{\bigcupdot}{\charfusion[\mathop]{\bigcup}{\cdot}}

\newcommand*{\mt}[1]{\text{\normalfont #1}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{theorem*}{Theorem}
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{definition*}{Definition}
\newtheorem{example}{Example}[section]
\newtheorem*{properties}{Properties}

\newtheoremstyle{algodesc}{}{}{}{}{\bfseries}{.}{ }{}%
\theoremstyle{algodesc}
\newtheorem{algodesc}{Algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand*{\colsquare}[3][-3.5pt]{\tikz[baseline=-0.5ex]\draw[#2, fill=#2] (0,#1) rectangle ++(#3,#3);}%
\definecolor{cmeet}{HTML}{B2DF8A}
\definecolor{cmideast}{HTML}{FDBF6F}
\definecolor{cstaff}{HTML}{A6CEE3}
\definecolor{cpolitics}{HTML}{33A02C}
\definecolor{cterror}{HTML}{E31A1C}
\definecolor{cforeign}{HTML}{FF7F00}
\definecolor{cpress}{HTML}{FB9A99}
\definecolor{chill}{HTML}{6A3D9A}
\definecolor{ccomm}{HTML}{1F78B4}


\begin{document}

\title{Exploring Hillary Clinton's Emails\thanks{STATS 601 final project.}}
\author{
    Leland Bybee, Roger Fan, Ryan Vaughn
}
\date{\today}

\maketitle


\section{Introduction}
From roughly 2008 to 2013, Hillary Clinton and some of her staff used a private family email server for most of he communication. This time period includes her tenure as U.S. Secretary of State, and has therefore become a controversial topic due to the possible security concerns of not using official government servers. Various investigations into the legality and appropriateness of the email server have been launched, and the issue has had/will potentiall have a large effect on Clinton's ongoing presidential campaign.

Due to several Freedom of Information Act (FOIA), the State Department has released the vast majority of the roughly 55,000 pages of emails to the public, leading to an unprecedented opportunity to explore the email usage of a major public figure.

Due to the size of the corpus, reading individual emails in the hope of discovering interesting characteristics is unrealistic. We therefore exploit statistical methods to break this vast analysis problem to a more manageable one, decreasing the scale so that we can more easily apply human and statistical analysis.

In order to tackle this problem, we use classical multi-dimensional scaling and spectral clustering in order to visualize and explore the corpus. We also use a statistical topic model, latent Dirichlet allocation (LDA), in order to identify and analyze the meanings and semantics. Finally, we use the LDA results and other metadata to examine how other covariates, such as email sender and time period sent, are related to the topic of an email.


\section{Data}
The State Department released the raw data in the form of roughly 30,000 pdfs of individual emails from the Clinton server.\footnote{Thanks to Ben Hamner and the Wall Street Journal for making the data processing code (\url{https://github.com/benhamner/hillary-clinton-emails}) and email pdfs (\url{http://graphics.wsj.com/hillary-clinton-email-documents/}) available, respectively.} We first process the pdfs to extract the raw text.\footnote{We used \texttt{pdftotext}, an open-source program used to extract text from pdf files.} From the raw email text, email headers and forward/response information are stripped, leaving only the subject line and body text.

All of our methods use a bag-of-words model, so from this raw data we construct a document term matrix containing vectors of word counts. Some standard data cleaning for text data is also performed, including the removal of punctuation and email addresses, word stemming (combining words with common roots, e.g. calling and called), and removing extremely common words (i.e. stop words) and extremely rare words (words that appear in less than 0.1\% of emails).

After this processing, we are left with a dataset of roughly 28,000 emails and a total vocabulary of over 3,000 words. Note that each word count vector is extremely sparse, so we need statistical methods that can apply in a sparse coordinate setting. Also, methods that can efficiently exploit this sparseness to reduce computation are preferred.


\section{Visualization}
Due to the large size and high dimensionality of the data, we must apply some dimensionality reduction in order to effectively visualize it. We therefore apply classical multi-dimensional scaling, which attempts to place each point in a much smaller dimension such that pairwise distances are preserved.

However, we expect standard Euclidean distance to poorly capture the actual relationships between vectors of word counts. In particular, Euclidean distance is affected by the total number of words, two emails with the exact same word distribution that differ in length could have a very large distance between them. In order to better capture pairwise relationships, we will use a distance metric based on the angles between vectors.

We define the cosine similarity between word frequency vectors $V$ and $W$ to be the cosine of the angle between the two vectors, calculated as
\begin{equation} \label{eq:cos_sim}
\cos(\phi) = \frac{\langle V, W \rangle}{\norm{V}\norm{W}}
\end{equation}
Since counts must be nonnegative, note that $\phi \leq \pi/2$. This implies that the cosine similarity is always between 0 and 1, with 0 corresponding to vectors that are multiples of each other and 1 corresponding to orthogonal vectors (i.e. no shared words). So we can define the cosine distance as
\begin{equation} \label{eq:cos_dist}
d(V, W) = 1 - \cos(\phi) = 1 - \frac{\langle V, W \rangle}{\norm{V}\norm{W}}
\end{equation}

Using this measure of distance, we can construct a distance matrix $D$ and apply MDS. The results for an 8,000 email subset are shown in Figure~\ref{fig:cluster}, plotted in both two and three dimensions. We can see several interesting patterns. The vast majority of emails (roughly 5,000) are contained in the main central grouping, with two large groupings that extend away. Besides these two ``arms,'' however, it is difficult to visually identify other significant structures.

\begin{figure}[htbp] \centering
  \begin{subfigure}[t]{.7\linewidth}
    \includegraphics[width=\linewidth]{../images/mds_2d_cluster.png}
    \caption{2 Dimensions} \label{fig:cluster:2d}
  \end{subfigure}
  \begin{subfigure}[t]{.7\linewidth}
    \includegraphics[width=\linewidth]{../images/mds_3d_cluster_1.png}
    \caption{3 Dimensions} \label{fig:cluster:3d}
  \end{subfigure}
  \caption{Visualization of a 8,000 email subset using classical multi-dimensional scaling and with coloring according to the results from spectral clustering. The similarity and distance metrics used for spectral clustering and MDS, respectively, are cosine similarity and distance as defined in Equations~\ref{eq:cos_sim} and~\ref{eq:cos_dist}.}
  \label{fig:cluster}
\end{figure}


\subsection{Spectral Clustering}
In order to better identify structure that may exist in the data, we attempt to apply clustering methods. However, it is important to choose an appropriate clustering method due to the high dimensionality and sparse nature of the data. In particular, we expect centroid-based methods such as Gaussian mixture models and $k$-means clustering to perform poorly in this setting.

Spectral clustering, however, exploits the information contained in the pairwise distances (or, equivalently, the similarities) between points. By using pairwise distances, spectral clustering is particularly well-suited to finding clusters that may not necessarily be spherical or ellipsoidal and that may lie along lower-dimensional manifolds.

To actually apply spectral clustering, we first construct the pairwise similarity matrix $S$ using our cosine similarity as defined in Equation~\ref{eq:cos_sim}. We define the degree matrix $D$ to be a diagonal matrix with $D_{ii} = \sum_j S_{ij}$, and construct the symmatrix normalized Laplacian matrix as
\begin{equation} \label{eq:laplacian}
L = I - D^{-1/2} S D^{-1/2}
\end{equation}
Then the eigenvectors corresponding to the smallest $k$ eigenvalues of $L$ are computed and $k$-means clustering is performed on these eigenvectors.

Figure~\ref{fig:cluster} classifies each point according to the results of spectral clustering with $k$ clusters. We can see that many of the cluster correspond to  the visually identifiable structures, including clusters that correspond to each of the ``arms.''

By investigating the individual emails, we can also get a sense of what each cluster consists of. For instance, clusters 2 and 4 consist of emails related to calls and communication. In this arm, those closer to the main central clump contain more conversation, while those farther out are much briefer and directly about the call (e.g. ``I'd like to call tomorrow.''). Cluster 3 consists entirely of ``minis,'' summaries of the days schedule sent to Clinton each morning. Emails from cluster 5 are generally requests to print materials, while those from cluster 6 are forwarded news articles.

In general, it seems that spectral clustering does a good job at identifying emails by their structure, but does not tell us much about the meaning of an email. We can tell that an email is regarding a call or is a news headline by what cluster it is in, but not what that call or headline is about. On a related note, it does not do a good job separating the ``regular'' emails. OVer 5,000 of the 8,000 emails depicted fall into clusters 1 or 8, which essentially consist of all the emails without specific identifiable structure. Ideally we would be able to further classify these emails according to subject matter, but clustering does not seem suited to this task.


\section{Topic Modeling}

To try and move beyond the limitations of spectral clustering and capture some of the content of the emails as well as structure, we next turn to latent Dirichlet allocation (LDA).  LDA is a popular form of topic modeling that has historically been effective for identifying clusters or "topics" in text corpuses\footnote{note on estimation}.  

LDA requires the number of topics to be specified as an input to the model, therefore one of the preliminary steps for topic model estimation is the selection of an appropriate number of topics.  Since our ultimate goal was to find sensible topics that could be used to understand the email corpus we initially turned to several coherence measures to perform our model selection, in particular we considered the UMass and UCI measures\footnote{add bib here}.  Coherence measures were developed as a way to quantify whether topics could make sense to a human observer.  However, the coherence of our topics didn't appear to vary much assuming we used more than 15 topics and less than 50.  As a result we turned to manual methods for selecting the number of topics that appeared to perform the best.  We estimated LDA for 5,10,...,75 topics and selected the model that appeared to be the most sensible to a human observer.  This left us with a 30 topic model.

Using our resulting topic model we want to answer a series of questions concerning our resulting topics and the email corpus.  First, can we identify a sensible structure in our topics that captures the structure we see with spectral clustering?  Second, can we identify informative content topics that correspond to real world events?  Finally, can we say anything about the email senders based on the topics discussed?

\subsection{Interpreting Topics}

MERGE HERE

ALSO TOPIC TABLE

At first, it may seem alarming that there are common and weak topics, but it's actually a good thing in many ways.  First, it's remarkable and incredibly useful from an analysis standpoint, that LDA accurately separates the common words into their own topics.  Clearly, words like ``think'', ``like'', and ``good'' are going to be present in any collection of documents, and they're not common enough like ``a'', ``and'', ``the'' to just eliminate from the data.  This means LDA is capable of separating out common words into their own topics so they can be incorporated or ignored as seen fit.  This is a huge advantage of this method.

As for the weak topics, not every topic has many, many words associated with it, so it's natural for some topics to have less words associated necessitating the algorithm to fill them in with other words.  For example, both terrorism topics are in the weak category.   Domestic terror at first glance could be a common category, but there are words below that seen such as ``death'', ``student'', ``group'', and ``hospit'' among others that help identify as Domestic Terror.  Topics such as this can come about as a common-sense thought that ``Domestic Terror'' should be a topic among Hillary Clinton's emails and this was the strongest of the weaker topics to fit this idea.  Is this right, or correct to label a topic in this manner?  There is no right or wrong in this sense when it comes down to it.  There is no statistical procedure that outlines the labeling of topics, so it is all done by eye.  

After the initial run-through to label each topic, more summary can be done to further categorize the various topics.  Looking through, we can place the topics together, see table \ref{tab:topic_cat} for these groups.

\begin{table}[htb] \centering
\begin{tabular}{rcl}
  \toprule
  \colsquare{cterror}{10pt} & Terrorism & 5, 22 \\
  \colsquare{cmideast}{10pt} & Middle East & 6, 18, 19, 27, 29 \\
  \colsquare{cforeign}{10pt} & Foreign Policy & 2, 7, 13, 21, 23, 26 \\
  \colsquare{cpolitics}{10pt} & Politics & 11, 17, 25 \\
  \colsquare{cstaff}{10pt} & Staff & 16, 20 \\
  \colsquare{cpress}{10pt} & Press & 4 \\
  \colsquare{chill}{10pt} & Hillary & 12 \\
  \colsquare{cmeet}{10pt} & Meetings & 1, 9, 10, 24, 28, 30 \\
  \colsquare{ccomm}{10pt} & Common & 3, 8, 14, 15 \\
  \bottomrule
\end{tabular}
\caption{Topic Categorization}
\label{tab:topic_cat}
\end{table}

The second thing that LDA gives is, for each email, a probability for every topic that the topic is included in the email.  Here, we will look at the relationships between topics and the frequencies that the topics are discussed.

If we look at the entire data set, LDA will not give any topics probabilities of zero for any email, even if that topic realistically doesn't come up at all.  For example, here are the first six emails in the data set with the probabilities (in percent here) that each of the 30 topics is discussed in the email.

PROBABILITY TABLE

A few things jump out.  First, every topic is at least 1\% in each email (at least apparently in this grouping, but it's this way throughout the entire set).  Second, some emails aren't about very much at all.  Email 1 has 3\% for everything and 9\% for topic 3, which was a common topic.  Contrast this with email 2, which has a low \% for every topic except 18, 19, 21, 25.  We could hypothesize that this email is about the Middle East, Foreign Policy, and Domestic Politics.  We could, of course, do this kind of procedure with email after email, but with 28,000 emails we need a way to get meaning from the whole group.

Before analyzing, we will remove the percentages for the common topics for each email, since we can realistically say that no email is about a topic with ``can'', ``also'', ``will'', etc., as the key words.  Next, we will zero any topic for each email that has less than 5\%.  The reason for this is the same as the logic in the above paragraph.  For email 2, we would naturally seek the topics with the higher percentages and ignore the rest.  After this we will rescale the percentages.

First, we can look at the number of emails that had each of the 26 non-common topics as the primary topic, or the topic with the highest percentage associated with it.  

\begin{table}[htb] \centering
\setlength{\tabcolsep}{1pt}
\begin{tabular}{cccccccccccccccccccccccccc}
  \toprule
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cpress}{16pt} &
  \colsquare[-3pt]{cmeet}{16pt} &
  \colsquare[-3pt]{cmideast}{16pt} &
  \colsquare[-3pt]{cmideast}{16pt} &
  \colsquare[-3pt]{cstaff}{16pt} &
  \colsquare[-3pt]{chill}{16pt} &
  \colsquare[-3pt]{cstaff}{16pt} &
  \colsquare[-3pt]{cpolitics}{16pt} &
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cmideast}{16pt} &
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cmideast}{16pt} &
  \colsquare[-3pt]{cterror}{16pt} &
  \colsquare[-3pt]{cmideast}{16pt} &
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cpolitics}{16pt} &
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cforeign}{16pt} &
  \colsquare[-3pt]{cpolitics}{16pt} &
  \colsquare[-3pt]{cterror}{16pt} \\
  21 & 1 & 28 & 30 & 10 & 9 & 4 & 24 & 18 & 29 & 16 & 12 & 20 &
  17 & 13 & 19 & 23 & 27 & 22 & 6 & 2 & 25 & 26 & 7 & 11 & 5 \\
  \midrule
  \multicolumn{13}{l}{Most Frequent} & \multicolumn{13}{r}{Least Frequent} \\
  \bottomrule
\end{tabular}
\setlength{\tabcolsep}{6pt}
\caption{Primary Topic Frequency}
\label{tab:topic_freq}
\end{table}

As we can see, the color-coding catches the eye, and the first unmistakable observation we can make is that Hillary Clinton and her staff talk a lot about meetings.  This is probably not too surprising for someone in her level of the US government.  As a high level official like Secretary of State, much of her day is probably spent in some sort of meeting or briefing getting filled in by her subordinates. 

Another quick observation that we can make is that there is a stark absence of domestic politics type issues such as abortion, health care, domestic economy, and others.  This, also, is not too surprising, as Hillary Clinton was Secretary of State, a position that mainly consists of foreign affairs.

Speaking of foreign affairs, the topic frequency for the purple above is much less than we might expect, except for 21.  This could be perceived as a bit unexpected from the Secretary of State.  This generalization might be unfair, however, because other specific foreign affair topics like 18 and 29 are higher and are about, for example, the Middle East.


\subsection{Types of Topics}
Talk about structural, common word, and semantic topics, including ``interesting'' vs. ``non-interesting'' topics, discuss strengths of model in comparison to MDS

\subsection{Topic Analysis}

We next want to get a sense of what the content topics look like and whether they correspond to real world events.  See table \ref{tab:content_topics}, for the top 10 words for a subset of six topics that we consider content topics.  These topics correspond to real world politically significant events.  For instances the Libya topic captures information about the Benghazi scandal as well the collapse of Gaddafi's administration.  

\begin{table}[h]
\centering
\scalebox{0.8}{
\begin{tabular}{cccccc}
\toprule
Israel & Elections & Libya & Afghanistan & Int. Dev. & Obama \\
\midrule
israel & democrat & libya & afghanistan & develop & presid \\
isra & republican & secur & pakistan & state & obama \\
peace & american & travel & afghan & support & said \\
palestinian & polit & libyan & militari & global & hous \\
netanyahu & parti & iraq & general & program & white \\
east & elect & embassi & karzai & effort & administr \\
negoti & obama & attack & offici & intern & polici \\
arab & percent & kill & war & work & aid \\
state & candid & march & forc & includ & advis \\
\bottomrule
\end{tabular}
}
\caption{Some interesting content topics}
\label{tab:content_topics}
\end{table}

Looking at the table we can see that the model does a good job of identifying words that we as human observers would associate with these events.  The election topic picks up on both of the primary political parties in the United States as well as words associated with political parties and elections, eg. polit(ics), parti(y), elect(ion), percent, candid(ate).  Similarly, the international development topics identifies words that we would associate with international development, eg. develop, support, global.  While this is only a subset of the content topics, we find that all of our content topics have this pattern.

While our content topics do appear to be sensible, we also want to get a sense of whether our topics appear in correct location in time.  For email we have a time stamp so we can sort our topic proportions by time to get a sense of whether our topics line up with real world events that correspond to the human interpretation of our topics.  See figure \ref{fig:topic_time_plots} for a plot of the mean monthly topic proportion fo the subset of content topics discussed above.  

Comparing our topic proportion plots to real world news events, we can see that our topics do a good job of picking up on the correct events.  In the Isreal topic the first peak of the topic proportions corresponds to the July 26th, 2010 joint Israeli and Romanian helicopter disaster, while the second peak corresponds to the September 9th, 2011 attack on the Israel embassy in Egypt.  Similarly, for the election topic each of the peaks corresponds to an election in the US.  Finally, the first peak of the Libya topic corresponds to the fall of Gaddafi's adminstration in October of 2011, while the second peak corresponds to the Benghazi attack on September 11th, 2012.  Again, while this shows only a subset of the topics we find that this pattern persists throughout our content topics\footnote{Comparable topic proportion plots are available on the github page for this project.}.

\begin{figure}[h]
\centering
\begin{subfigure}[Israel]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot6.pdf}
    \caption{Israel} \label{fig:t1}
\end{subfigure}
\begin{subfigure}[Election]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot11.pdf}
    \caption{Election} \label{fig:t2}
\end{subfigure}
\begin{subfigure}[Libya]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot18.pdf}
    \caption{Libya} \label{fig:t3}
\end{subfigure}
\begin{subfigure}[Afghanistan]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot27.pdf}
    \caption{Afghanistan} \label{fig:t4}
\end{subfigure}
\begin{subfigure}[Int. Dev.]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot23.pdf}
    \caption{Int. Dev.} \label{fig:t5}
\end{subfigure}
\begin{subfigure}[Obama]{.30\linewidth}
    \includegraphics[width=\linewidth]{../images/time_plot25.pdf}
    \caption{Obama} \label{fig:t6}
\end{subfigure}
\caption{Visualization of the average monthly topic proportion for a subset of content topics over time.}
\label{fig:topic_time_plots}
\end{figure}


\section{Email Sender Prediction}

Finally, we want to consider whether we can say anything interesting about the senders based on our topic model.  In total 395 unique senders exist in our email corpus, however, only 14 senders sent more than 100 emails.  We focus on this subset of 14 senders for the remainder of our analysis.  This leaves us with a corpus of 25809 emails.  We use the topic proportions from the model estimated on the full corpus for this subset.

\begin{table}[h]
\centering
\label{topic_sources}
\scalebox{0.70}{
\begin{tabular}{cccccc}
\toprule
Israel & Elections & Libya & Afghanistan & Int. Dev. & Obama \\
\midrule
Sidney Blumenthal & SB & Huma Abedin & Judith McHale & JM & SB \\
(SB) & & (HA) & (JM) & & \\
\noalign{\vskip 5mm}
HA & Philippe Reines & Wendy Sherman & HA & Melanne Verveer & PR \\
& (PR) & (WS) & & (MV) & \\
\noalign{\vskip 5mm}
Jake Sullivan & JM & JS & MV & Anne-Marie & Cherly Mills \\
(JS) & & & & Slaughter (AMS) & (CM)\\
\noalign{\vskip 5mm}
AMS & CM & Monica Hanley & JS & CM & HA \\
& & (MH) & & & \\
\noalign{\vskip 5mm}
Hillary Clinton & HA & SB & Richard Verma & JS & HC \\
(HC) & & & (RV) & & \\
\bottomrule
\end{tabular}
}
\caption{Primary senders for interesting topics}
\label{tab:top_senders}
\end{table}

See table \ref{tab:top_senders} for a ranking of the 14 senders for the subset of content topics explored above.  This table presents the top five senders for each of the topics based on the average topic proportion for each sender.  The sorting that we get back seems to fit with a human understanding of each of the senders, Sidney Blumenthal, who appears to be most associated with the Israel, Election and Obama topics is a long standing advisor to the Clinton family who has written extensively on US politics as well as foreign policy.  Similarly, Huma Abedin, who is most associated with Libya was a key figure during the Benghazi hearings and was generally strongly associated with foreign policy, particularlly in the Middle East while Hillary Clinton's Deputy Chief of Staff.  Finally, Judith McHale, who is most associated with the Afghanistan and international development topic was Under Secretary of State for Public Diplomacy and Public Affairs during the early portion of the email corpus under Hillary.  She also has been strongly associated with a number of philanthropic efforts.  It may be interesting to note that Hillary does not appear to be strongly associated with many of our subset of content topics.  This pattern persists through the remainder of the content topics, in general, Hillary does not appear to send many emails strongly associated with most of the content topics.

\subsection{Multinomial Logistic Regression}

While the above results do give some sense of which senders are most associated with which topics, we next want to formalize this approach and get more general results that can more easily show us which senders are most related to each topic.  To approach this problem we turn to multinomial logistic regression as a solution.  Multinomial logistic regression generalizes the logistic regression approach to the case with more labels than two.  Part of the output of multinomial logistic regression is a $P \times K$ matrix of coefficients corresponding to how strongly related each of the $K$ variables of interest are related to each of the $P$ labels.

For our particular case we estimate a model using the $30$ topics as our explanatory variables and the $14$ senders as our labels.  We use a training subset of 23229 emails and their corresponding topic proportions to train our model and a subset of 2580 emails for testing.  See table \ref{tab:mlr_success} for the success rate for our testing data.  Overall the model appears to perform well, correctly identifying roughly 30\% of the senders correctly.  For Hillary we correctly identify 74\% of the emails.

\begin{table}[h]
\centering
%\scalebox{0.7}{
\begin{tabular}{ccc}
\toprule
Source & Success Rate & Testing Observations \\
\midrule
Hillary Clinton & 0.74 & 849 \\
Philippe Reines & 0.06 & 34 \\
Claire Coleman & 0.52 & 27 \\
Lauren Jiloty & 0.42 & 71 \\
Huma Abedin & 0.36 & 376 \\
Jake Sullivan & 0.23 & 410 \\
Sidney Blumenthal & 0.29 & 87 \\
Cherly Mills & 0.31 & 491 \\
Anne-Marie Slaughter & 0.36 & 42 \\
Monica Hanley & 0.09 & 53 \\
Judith McHale & 0.25 & 28 \\
Robert Russo & 0.00 & 10 \\
Richard Verma & 0.26 & 19 \\
Wendy Sherman & 0.08 & 12 \\
Melanne Verveer & 0.30 & 30 \\
Lona Valmoro & 0.34 & 41 \\
\bottomrule
\end{tabular}
%}
\caption{Multinomial logistic regression successes}
\label{tab:mlr_success}
\end{table}

To relate these results back to our earlier analysis we want to look at the coefficients for the multinomial logistic regression model as this should give us a sense of how strongly each sender is associated with the different topics.  See figure \ref{fig:coefficients} for a heatmap of the resulting coefficient matrix\footnote{Note that the coefficients are standardized and we threshold all standardized coefficients above or below 2 to make the heatmap easier to interpret.}.

The results we see here all us to tell a story about the email senders that corresponds to our intution based on each of the sender's backgrounds.  Sidney Blumenthal is strongly associated with the Middle East, foreign policy and general politics topics.  He doesn't have much to say about Hillary or her significance to the press and generally doesn't talk muhc about meetings.  Huma Abedin and Jake Sullivan provide advice on the Middle east and foreign policy.  Judith McHale focuses her emails on foreign policy and handling press issues.  While all this is going on Hillary spends most of her time discussing meetings.

In general the story that emerges is that while Hillary does not say much herself about world events, she has surrounded herself with a set of advisors who are more than willing to say a great deal about the content topics.  She then spends most of her time on email coordinating meetings, telling people to print emails and generally coordinating the information gathered from her advisors.

\begin{figure}[htb] \centering
  \includegraphics[width=0.95\linewidth]{../images/coefficients.pdf}
  \caption{Standardized coefficients from a multinomial logistic regression of email sender on LDA topic proportions.}
  \label{fig:coefficients}
\end{figure}


\section{Conclusion}

We have presented a series of results to attempt to make a large corpus of emails that would be difficult to parse manually approachable to the human user.  We have been able to identify general structures in the email corpus using both spectral clustering and LDA.  For LDA we find that we can seperate out content topics from structural topics and that the topics we get back are sensible and align with what we would expect in the real world.  Additionally, we find that we can say something interesting about the senders for our email corpus.

There are many ways that this work could be expanded, and our work should be considered explorartory and a starting place more than anything else.  While we begin to dive into some possible extensions when we discuss senders this idea could easily be taken further.  Information on recievers, while not as clean as sender information could also be incorporated.  This could allows us to build a better model of interactions within the email corpus.  Additionally, variables beyond just the topic proportions could be incorporated into our model, one clear example of this is a time spline variable to account for the possibility that different senders are more important for different topics over time.

Overall, we have tried to tell a story about the Hillary email corpus.  We have only scratched the surface of our understanding of this corpus but we believe that we have layed out a good set of tools and a strong approach to move forward.

\end{document}
